
# ğŸ§­ Vectors in Machine Learning

_Essential Mathematics for ML â€” Structured Notes_

---

## ğŸ“Œ 1. What is a Vector?

A **vector** is a mathematical object that has:

- **Magnitude (length)**
    
- **Direction**
    

### Formal definition

A vector is an element of a **vector space**, which supports:

1. **Vector addition**
    
2. **Scalar multiplication**
    

### Representation

- **Row vector:** `[vâ‚ vâ‚‚ ... vâ‚™]`
    
- **Column vector:**
    
    ```
    [ vâ‚
      vâ‚‚
      â‹®
      vâ‚™ ]
    ```
    

---

## ğŸ“Œ 2. Vectors in â„â¿

A vector  
`v = (vâ‚, vâ‚‚, â€¦, vâ‚™)`  
belongs to the vector space **â„â¿** if all components are real numbers.

### Examples

- **â„Â²:** (1, 2)
    
- **â„Â³:** (1, 2, 3)
    
- Higher dimensions exist but cannot be visualized.
    

---

## ğŸ“Œ 3. Geometric Interpretation

- Each component = coordinate along an axis
    
- In 2D â†’ (x, y)
    
- In 3D â†’ (x, y, z)
    

A vector = **arrow from origin** representing direction + length.

---

# ğŸ§® Vector Algebra

---

## âœ”ï¸ 4. Addition & Subtraction

Defined **component-wise**.

Given  
`vâ‚ = (xâ‚, xâ‚‚, â€¦, xâ‚™)`  
`vâ‚‚ = (yâ‚, yâ‚‚, â€¦, yâ‚™)`

### Addition

```
vâ‚ + vâ‚‚ = (xâ‚ + yâ‚, xâ‚‚ + yâ‚‚, â€¦, xâ‚™ + yâ‚™)
```

### Subtraction

```
vâ‚ - vâ‚‚ = (xâ‚ - yâ‚, xâ‚‚ - yâ‚‚, â€¦, xâ‚™ - yâ‚™)
```

---

## âœ”ï¸ 5. Dot Product (Inner Product)

Given two vectors in â„â¿:

```
vâ‚ Â· vâ‚‚ = Î£ (xáµ¢ yáµ¢)
```

Example in â„Â³:  
`(1, 1, -1) Â· (2, 3, 1) = 4`

â†’ Result is always a **scalar**.

---

## âœ”ï¸ 6. Magnitude (Length / Norm)

```
â€–vâ€– = âˆš(v Â· v)
```

Example:  
`v = (1, -1, 2)`

```
â€–vâ€– = âˆš(1Â² + (-1)Â² + 2Â²) = âˆš6
```

---

## âœ”ï¸ 7. Angle Between Two Vectors

```
cos Î¸ = (vâ‚ Â· vâ‚‚) / (â€–vâ‚â€– â€–vâ‚‚â€–)
```
```
sin Î¸ = (vâ‚ x vâ‚‚) / (â€–vâ‚â€– â€–vâ‚‚â€–)
```

So,

```
Î¸ = cosâ»Â¹( (vâ‚ Â· vâ‚‚) / (â€–vâ‚â€– â€–vâ‚‚â€–) )
```
```
Î¸ = sinâ»Â¹( (vâ‚ x vâ‚‚) / (â€–vâ‚â€– â€–vâ‚‚â€–) )
```
---

# ğŸ”— 8. Linear Combination

Given vectors `{vâ‚, vâ‚‚, â€¦, vâ‚–}`:

A **linear combination** is:

```
Î±â‚vâ‚ + Î±â‚‚vâ‚‚ + ... + Î±â‚–vâ‚–
```

Î±â€™s are scalars (usually real numbers).

Example:  
Using vectors vâ‚, vâ‚‚, vâ‚ƒ in â„Â³, any vector formed like:

```
Î±â‚vâ‚ + Î±â‚‚vâ‚‚ + Î±â‚ƒvâ‚ƒ
```

is a linear combination.

---

# ğŸ” 9. Linear Independence & Dependence

## âœ”ï¸ Linear Independence (LI)

Set `{vâ‚, vâ‚‚, â€¦, vâ‚™}` is LI if:

```
Î±â‚vâ‚ + Î±â‚‚vâ‚‚ + ... + Î±â‚™vâ‚™ = 0
```

only when:

```
Î±â‚ = Î±â‚‚ = ... = Î±â‚™ = 0
```

### Intuition

You **cannot build** one vector using others.

---

## âŒ Linear Dependence (LD)

Vectors are LD if:

```
Î±â‚vâ‚ + Î±â‚‚vâ‚‚ + ... = 0
```

for **some non-zero scalars**.

### Example

(1,1) and (3,3) â†’ LD because:

```
3(1,1) - 1(3,3) = 0
```

---

## Important Remarks

- In **â„â¿**, any set of **> n vectors is LD**
    
- Any set **containing the zero vector is LD**
    

---

# ğŸ¯ 10. Orthogonal & Orthonormal Vectors

## âœ”ï¸ Orthogonal

```
váµ¢ Â· vâ±¼ = 0, for all i â‰  j
```

â†’ They are perpendicular.

### Important

Orthogonal vectors are **automatically linearly independent**.

---

## âœ”ï¸ Orthonormal

Set is orthonormal if:

1. Vectors are orthogonal
    
2. Each vector has length = 1
    

Example in â„Â²:

```
(1/âˆš2, 1/âˆš2)
(1/âˆš2, -1/âˆš2)
```

---

# ğŸ“Š 11. Vectors as Feature Vectors in ML

Consider this dataset:

|Employee|Height|Weight|
|---|---|---|
|Eâ‚|Î±â‚|Î²â‚|
|Eâ‚‚|Î±â‚‚|Î²â‚‚|
|â€¦|â€¦|â€¦|
|Eâ‚–|Î±â‚–|Î²â‚–|

For employee Eâ‚‚:

```
Feature vector = ( height, weight ) = (Î±â‚‚, Î²â‚‚)
```

In ML:

- **rows** = samples
    
- **columns** = features
    
- each row vector = **feature vector**
    

---

# ğŸ 12. Python / NumPy Operations

```python
import numpy as np

v = np.array([1, -1, 2])
w = np.array([2, 5, 2])

print(v + w)          # Addition
print(v - w)          # Subtraction
print(3 * v)          # Scalar multiplication
print(np.linalg.norm(v)) # Length
print(np.dot(v, w))      # Dot product
```

Outputs include addition, subtraction, norm, and dot product.

---

